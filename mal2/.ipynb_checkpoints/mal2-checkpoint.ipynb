{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb05f03283b3829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:14:17.800446661Z",
     "start_time": "2025-11-10T10:14:16.917626754Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-10T10:47:19.248488Z",
     "iopub.status.busy": "2025-11-10T10:47:19.248227Z",
     "iopub.status.idle": "2025-11-10T10:47:21.113445Z",
     "shell.execute_reply": "2025-11-10T10:47:21.112024Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, zipfile, numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:14:19.334016851Z",
     "start_time": "2025-11-10T10:14:17.802447910Z"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-10T10:47:21.116863Z",
     "iopub.status.busy": "2025-11-10T10:47:21.116503Z",
     "iopub.status.idle": "2025-11-10T10:47:22.469898Z",
     "shell.execute_reply": "2025-11-10T10:47:22.468305Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_zip(zip_path: str):\n",
    "    contents, labels, names = [], [], []\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        for name in z.namelist():\n",
    "            if name.endswith(\"/\") or name.endswith(\".labels\"):\n",
    "                continue\n",
    "            base = os.path.basename(name)\n",
    "            if not (base.endswith(\".0\") or base.endswith(\".1\")):\n",
    "                continue\n",
    "            lab = int(base.rsplit(\".\", 1)[1])\n",
    "            contents.append(z.read(name))\n",
    "            labels.append(lab)\n",
    "            names.append(name)\n",
    "    return names, contents, np.asarray(labels, dtype=int)\n",
    "\n",
    "def load_test_zip(zip_path: str):\n",
    "    names, contents = [], []\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        for name in z.namelist():\n",
    "            if name.endswith(\"/\") or name.endswith(\".labels\"):\n",
    "                continue\n",
    "            contents.append(z.read(name))\n",
    "            names.append(name)\n",
    "    return names, contents\n",
    "\n",
    "names, pdf_bytes, labels = load_train_zip(\"pdf-train.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c088f693ded29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:30:47.738104981Z",
     "start_time": "2025-11-10T10:30:47.724971443Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-10T10:47:22.473424Z",
     "iopub.status.busy": "2025-11-10T10:47:22.473169Z",
     "iopub.status.idle": "2025-11-10T10:47:22.486429Z",
     "shell.execute_reply": "2025-11-10T10:47:22.485565Z"
    }
   },
   "outputs": [],
   "source": [
    "from minimal_pdfid import PDFiD\n",
    "\n",
    "def _attr_float(root, name):\n",
    "    v = root.getAttribute(name)\n",
    "    return float(v) if v not in ('', 'N/A') else 0.0\n",
    "\n",
    "def _attr_int(root, name):\n",
    "    v = root.getAttribute(name)\n",
    "    return int(v) if v != '' else 0\n",
    "\n",
    "def extract_features(path_or_bytes):\n",
    "    xml = PDFiD(path_or_bytes, allNames=True, extraData=True, force=True)\n",
    "    root = xml.documentElement\n",
    "\n",
    "    total_entropy = _attr_float(root, \"TotalEntropy\")\n",
    "    stream_entropy = _attr_float(root, \"StreamEntropy\")\n",
    "    non_stream_entropy = _attr_float(root, \"NonStreamEntropy\")\n",
    "    total_count = _attr_int(root, \"TotalCount\")\n",
    "    stream_count = _attr_int(root, \"StreamCount\")\n",
    "    non_stream_count = _attr_int(root, \"NonStreamCount\")\n",
    "    count_eof = _attr_int(root, \"CountEOF\")\n",
    "    chars_after_last_eof = _attr_int(root, \"CountCharsAfterLastEOF\")\n",
    "\n",
    "    def kw(name):\n",
    "        try:\n",
    "            node = [n for n in root.getElementsByTagName(\"Keywords\")[0].childNodes\n",
    "                    if n.getAttribute(\"Name\") == name][0]\n",
    "            return int(node.getAttribute(\"Count\") or 0)\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    obj = kw(\"obj\")\n",
    "    encrypt = kw(\"/Encrypt\")\n",
    "    js = kw(\"/JS\")\n",
    "    javascript = kw(\"/JavaScript\")\n",
    "    aa = kw(\"/AA\")\n",
    "    openaction = kw(\"/OpenAction\")\n",
    "    launch = kw(\"/Launch\")\n",
    "    richmedia = kw(\"/RichMedia\")\n",
    "    embeddedfile = kw(\"/EmbeddedFile\")\n",
    "    acroform = kw(\"/AcroForm\")\n",
    "    jbig2 = kw(\"/JBIG2Decode\")\n",
    "    xfa = kw(\"/XFA\")\n",
    "    colors_gt_2_24 = kw(\"/Colors > 2^24\")\n",
    "    js_per_obj = round((js + javascript) / max(obj, 1), 4)\n",
    "    stream_entropy_ratio = round(stream_entropy / max(total_entropy, 1e-9), 4) if total_entropy > 0 else 0.0\n",
    "    stream_bytes_ratio = round(stream_count / max(total_count, 1), 4)\n",
    "\n",
    "    feats = {\n",
    "        # \"count_eof\": count_eof,\n",
    "        # \"chars_after_last_eof\": chars_after_last_eof,\n",
    "        # \"total_entropy\": round(total_entropy, 4),\n",
    "        # \"stream_entropy\": round(stream_entropy, 4),\n",
    "        # \"non_stream_entropy\": round(non_stream_entropy, 4),\n",
    "        # \"total_bytes\": total_count,\n",
    "        # \"stream_bytes\": stream_count,\n",
    "        # \"non_stream_bytes\": non_stream_count,\n",
    "        # \"stream_bytes_ratio\": stream_bytes_ratio,\n",
    "        # \"stream_entropy_ratio\": stream_entropy_ratio,\n",
    "        \"js_count\": js,\n",
    "        # \"javascript_count\": javascript,\n",
    "        # \"aa_count\": aa,\n",
    "        # \"openaction_count\": openaction,\n",
    "        # \"launch_count\": launch,\n",
    "        # \"richmedia_count\": richmedia,\n",
    "        # \"embeddedfile_count\": embeddedfile,\n",
    "        # \"acroform_count\": acroform,\n",
    "        # \"jbig2decode_count\": jbig2,\n",
    "        # \"xfa_count\": xfa,\n",
    "        # \"colors_gt_2_24_count\": colors_gt_2_24,\n",
    "        # \"encrypt_count\": encrypt,\n",
    "        # \"js_per_obj\": js_per_obj,\n",
    "        # \"total_entropy_rounded\": round(total_entropy, 2),\n",
    "        # \"stream_entropy_rounded\": round(stream_entropy, 2),\n",
    "    }\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c49abd8ee8023e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:30:50.374004813Z",
     "start_time": "2025-11-10T10:30:50.365785904Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-10T10:47:22.490184Z",
     "iopub.status.busy": "2025-11-10T10:47:22.489960Z",
     "iopub.status.idle": "2025-11-10T10:47:22.493712Z",
     "shell.execute_reply": "2025-11-10T10:47:22.492769Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_to_matrix(pdf_bytes):\n",
    "    rows = [extract_features(b) for b in pdf_bytes]\n",
    "    df = pd.DataFrame(rows).fillna(0.0)\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    cols = df.columns.tolist()\n",
    "    return X, cols, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3fc6e7d9387a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:47:09.692800891Z",
     "start_time": "2025-11-10T10:30:51.724577872Z"
    },
    "execution": {
     "iopub.execute_input": "2025-11-10T10:47:22.496014Z",
     "iopub.status.busy": "2025-11-10T10:47:22.495798Z",
     "iopub.status.idle": "2025-11-10T11:16:33.907379Z",
     "shell.execute_reply": "2025-11-10T11:16:33.905664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Lade Trainingsdaten…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Extrahiere Features (Train)…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] X_train: (6144, 1), Features: ['js_count']\n",
      "[+] GridSearchCV (CV, refit auf ALLEN Trainingsdaten)…\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Beste Parameter: {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "[+] Lade Testdaten…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Extrahiere Features (Test)…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Erzeuge Vorhersagen…\n",
      "[+] Schreibe output.csv …\n",
      "[+] Fertig: output.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_zip = \"pdf-train.zip\"\n",
    "    test_zip  = \"pdf-test.zip\"\n",
    "\n",
    "    print(\"[+] Lade Trainingsdaten…\")\n",
    "    train_names, train_files, y = load_train_zip(train_zip)\n",
    "\n",
    "    print(\"[+] Extrahiere Features (Train)…\")\n",
    "    X_train, feat_names, _ = features_to_matrix(train_files)\n",
    "    print(f\"[+] X_train: {X_train.shape}, Features: {feat_names}\")\n",
    "\n",
    "    print(\"[+] GridSearchCV (CV, refit auf ALLEN Trainingsdaten)…\")\n",
    "    grid = GridSearchCV(\n",
    "        Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm\", SVC(probability=False, random_state=42))\n",
    "        ]),\n",
    "        {\n",
    "            \"svm__kernel\": [\"rbf\", \"linear\"],\n",
    "            \"svm__C\": [1, 10, 100],\n",
    "            \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "        },\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "    grid.fit(X_train, y)\n",
    "    pipe = grid.best_estimator_\n",
    "    print(\"[+] Beste Parameter:\", grid.best_params_)\n",
    "\n",
    "    print(\"[+] Lade Testdaten…\")\n",
    "    test_files, test_pdf = load_test_zip(test_zip)\n",
    "\n",
    "    print(\"[+] Extrahiere Features (Test)…\")\n",
    "    X_test, _, _ = features_to_matrix(test_pdf)\n",
    "\n",
    "    print(\"[+] Erzeuge Vorhersagen…\")\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    print(\"[+] Schreibe output.csv …\")\n",
    "    with open(\"output.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for path, pred in zip(test_files, predictions):\n",
    "            f.write(f\"{path};{int(pred)}\\n\")\n",
    "\n",
    "    print(\"[+] Fertig: output.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
