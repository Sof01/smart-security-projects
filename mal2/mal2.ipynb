{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb05f03283b3829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:14:17.800446661Z",
     "start_time": "2025-11-10T10:14:16.917626754Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, zipfile, numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:14:19.334016851Z",
     "start_time": "2025-11-10T10:14:17.802447910Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_train_zip(zip_path: str):\n",
    "    contents, labels, names = [], [], []\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        for name in z.namelist():\n",
    "            if name.endswith(\"/\") or name.endswith(\".labels\"):\n",
    "                continue\n",
    "            base = os.path.basename(name)\n",
    "            if not (base.endswith(\".0\") or base.endswith(\".1\")):\n",
    "                continue\n",
    "            lab = int(base.rsplit(\".\", 1)[1])\n",
    "            contents.append(z.read(name))\n",
    "            labels.append(lab)\n",
    "            names.append(name)\n",
    "    return names, contents, np.asarray(labels, dtype=int)\n",
    "\n",
    "def load_test_zip(zip_path: str):\n",
    "    names, contents = [], []\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        for name in z.namelist():\n",
    "            if name.endswith(\"/\") or name.endswith(\".labels\"):\n",
    "                continue\n",
    "            contents.append(z.read(name))\n",
    "            names.append(name)\n",
    "    return names, contents\n",
    "\n",
    "names, pdf_bytes, labels = load_train_zip(\"pdf-train.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c088f693ded29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:30:47.738104981Z",
     "start_time": "2025-11-10T10:30:47.724971443Z"
    }
   },
   "outputs": [],
   "source": [
    "from minimal_pdfid import PDFiD\n",
    "\n",
    "def _attr_float(root, name):\n",
    "    v = root.getAttribute(name)\n",
    "    return float(v) if v not in ('', 'N/A') else 0.0\n",
    "\n",
    "def _attr_int(root, name):\n",
    "    v = root.getAttribute(name)\n",
    "    return int(v) if v != '' else 0\n",
    "\n",
    "def extract_features(path_or_bytes):\n",
    "    xml = PDFiD(path_or_bytes, allNames=True, extraData=True, force=True)\n",
    "    root = xml.documentElement\n",
    "\n",
    "    total_entropy = _attr_float(root, \"TotalEntropy\")\n",
    "    stream_entropy = _attr_float(root, \"StreamEntropy\")\n",
    "    non_stream_entropy = _attr_float(root, \"NonStreamEntropy\")\n",
    "    total_count = _attr_int(root, \"TotalCount\")\n",
    "    stream_count = _attr_int(root, \"StreamCount\")\n",
    "    non_stream_count = _attr_int(root, \"NonStreamCount\")\n",
    "    count_eof = _attr_int(root, \"CountEOF\")\n",
    "    chars_after_last_eof = _attr_int(root, \"CountCharsAfterLastEOF\")\n",
    "\n",
    "    def kw(name):\n",
    "        try:\n",
    "            node = [n for n in root.getElementsByTagName(\"Keywords\")[0].childNodes\n",
    "                    if n.getAttribute(\"Name\") == name][0]\n",
    "            return int(node.getAttribute(\"Count\") or 0)\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    obj = kw(\"obj\")\n",
    "    encrypt = kw(\"/Encrypt\")\n",
    "    js = kw(\"/JS\")\n",
    "    javascript = kw(\"/JavaScript\")\n",
    "    aa = kw(\"/AA\")\n",
    "    openaction = kw(\"/OpenAction\")\n",
    "    launch = kw(\"/Launch\")\n",
    "    richmedia = kw(\"/RichMedia\")\n",
    "    embeddedfile = kw(\"/EmbeddedFile\")\n",
    "    acroform = kw(\"/AcroForm\")\n",
    "    jbig2 = kw(\"/JBIG2Decode\")\n",
    "    xfa = kw(\"/XFA\")\n",
    "    colors_gt_2_24 = kw(\"/Colors > 2^24\")\n",
    "    js_per_obj = round((js + javascript) / max(obj, 1), 4)\n",
    "    stream_entropy_ratio = round(stream_entropy / max(total_entropy, 1e-9), 4) if total_entropy > 0 else 0.0\n",
    "    stream_bytes_ratio = round(stream_count / max(total_count, 1), 4)\n",
    "\n",
    "    feats = {\n",
    "         \"count_eof\": count_eof,\n",
    "         \"chars_after_last_eof\": chars_after_last_eof,\n",
    "         \"total_entropy\": round(total_entropy, 4),\n",
    "         \"stream_entropy\": round(stream_entropy, 4),\n",
    "         \"non_stream_entropy\": round(non_stream_entropy, 4),\n",
    "         \"total_bytes\": total_count,\n",
    "         \"stream_bytes\": stream_count,\n",
    "         \"non_stream_bytes\": non_stream_count,\n",
    "         \"stream_bytes_ratio\": stream_bytes_ratio,\n",
    "         \"stream_entropy_ratio\": stream_entropy_ratio,\n",
    "         \"js_count\": js,\n",
    "         \"javascript_count\": javascript,\n",
    "         \"aa_count\": aa,\n",
    "         \"openaction_count\": openaction,\n",
    "         \"launch_count\": launch,\n",
    "         \"richmedia_count\": richmedia,\n",
    "         \"embeddedfile_count\": embeddedfile,\n",
    "         \"acroform_count\": acroform,\n",
    "         \"jbig2decode_count\": jbig2,\n",
    "         \"xfa_count\": xfa,\n",
    "         \"colors_gt_2_24_count\": colors_gt_2_24,\n",
    "         \"encrypt_count\": encrypt,\n",
    "         \"js_per_obj\": js_per_obj,\n",
    "    }\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c49abd8ee8023e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:30:50.374004813Z",
     "start_time": "2025-11-10T10:30:50.365785904Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_to_matrix(pdf_bytes):\n",
    "    rows = [extract_features(b) for b in pdf_bytes]\n",
    "    df = pd.DataFrame(rows).fillna(0.0)\n",
    "    X = df.to_numpy(dtype=float)\n",
    "    cols = df.columns.tolist()\n",
    "    return X, cols, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fc6e7d9387a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T10:47:09.692800891Z",
     "start_time": "2025-11-10T10:30:51.724577872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Lade Trainingsdaten…\n",
      "[+] Extrahiere Features (Train)…\n",
      "[+] X_train_full: (6144, 23), Features: 23\n",
      "[+] Split: Train (4915, 23), Validation (1229, 23)\n",
      "[+] GridSearchCV (5-fold CV, Training auf Split-Train)…\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def main():\n",
    "    train_zip = \"pdf-train.zip\"\n",
    "    test_zip  = \"pdf-test.zip\"\n",
    "\n",
    "    print(\"[+] Lade Trainingsdaten…\")\n",
    "    train_names, train_files, y = load_train_zip(train_zip)\n",
    "\n",
    "    print(\"[+] Extrahiere Features (Train)…\")\n",
    "    X_train_full, feat_names, _ = features_to_matrix(train_files)\n",
    "    print(f\"[+] X_train_full: {X_train_full.shape}, Features: {len(feat_names)}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Train-Test-Split für interne Validierung\n",
    "    # -----------------------------\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(f\"[+] Split: Train {X_train.shape}, Validation {X_val.shape}\")\n",
    "\n",
    "    print(\"[+] GridSearchCV (5-fold CV, Training auf Split-Train)…\")\n",
    "    grid = GridSearchCV(\n",
    "        Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm\", SVC(probability=False, random_state=42))\n",
    "        ]),\n",
    "        {\n",
    "            \"svm__kernel\": [\"rbf\", \"linear\"],\n",
    "            \"svm__C\": [1, 10, 100],\n",
    "            \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "        },\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Balanced Accuracy auf Hold-out Validation anzeigen\n",
    "    # -----------------------------\n",
    "    y_pred_val = grid.predict(X_val)\n",
    "    bal_acc = balanced_accuracy_score(y_val, y_pred_val)\n",
    "    print(f\"[+] Balanced Accuracy (Hold-out Validation): {bal_acc:.4f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Refit auf allen Trainingsdaten\n",
    "    # -----------------------------\n",
    "    print(\"[+] Refit auf allen Trainingsdaten…\")\n",
    "    pipe = grid.best_estimator_\n",
    "    pipe.fit(X_train_full, y)\n",
    "    print(\"[+] Beste Parameter:\", grid.best_params_)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Testdaten laden und vorhersagen\n",
    "    # -----------------------------\n",
    "    print(\"[+] Lade Testdaten…\")\n",
    "    test_files, test_pdf = load_test_zip(test_zip)\n",
    "\n",
    "    print(\"[+] Extrahiere Features (Test)…\")\n",
    "    X_test, _, _ = features_to_matrix(test_pdf)\n",
    "\n",
    "    print(\"[+] Erzeuge Vorhersagen…\")\n",
    "    predictions = pipe.predict(X_test)\n",
    "\n",
    "    print(\"[+] Schreibe output.csv …\")\n",
    "    with open(\"output.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for path, pred in zip(test_files, predictions):\n",
    "            f.write(f\"{path};{int(pred)}\\n\")\n",
    "\n",
    "    print(\"[+] Fertig: output.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
