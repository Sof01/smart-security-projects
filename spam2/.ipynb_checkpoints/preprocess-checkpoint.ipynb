{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da5e16f",
   "metadata": {},
   "source": [
    "Parsing the Emails (Mailbox format)\n",
    "\n",
    "subject\n",
    "Body\n",
    "Absender\n",
    "time\n",
    "past messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5026a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stud17/python/spam2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f82fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "from email import policy\n",
    "\n",
    "def extract_body_from_email(path):\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        msg = email.message_from_file(f)\n",
    "    \n",
    "    # If multipart, go through parts\n",
    "    if msg.is_multipart():\n",
    "        parts = []\n",
    "        for part in msg.walk():\n",
    "            if part.get_content_type() == 'text/plain':  # we only want the readable part\n",
    "                charset = part.get_content_charset()\n",
    "                payload = part.get_payload(decode=True)\n",
    "                if payload is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    text = payload.decode(charset or 'utf-8', errors='ignore')\n",
    "                except (LookupError, UnicodeDecodeError):\n",
    "                    text = payload.decode('utf-8', errors='ignore')\n",
    "                parts.append(text)\n",
    "        return '\\n'.join(parts)\n",
    "    else:\n",
    "        # Single-part message\n",
    "        payload = msg.get_payload(decode=True)\n",
    "        charset = msg.get_content_charset()\n",
    "        try:\n",
    "            return payload.decode(charset or 'utf-8', errors='ignore')\n",
    "        except (LookupError, UnicodeDecodeError):\n",
    "            return payload.decode('utf-8', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9a888",
   "metadata": {},
   "source": [
    "test in one email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1214b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Not on the list, please CC me on replies)\n",
      "\n",
      "hey,\n",
      " ia64 cpus have dropped hardware i386 support in exchange for non-free\n",
      "software emulation, known as \"IA-32 EL\". I took a cursory look at the\n",
      "license, and I'm wondering if its even viable to upload to non-free.\n",
      "\n",
      "The text of this license is available here:\n",
      "  http://www3.intel.com/cd/software/products/asmo-na/eng/219741.htm\n",
      "\n",
      "It seems pretty clear that the intent is to permit redistribution, but\n",
      "I'm unsure about some of the restrictions. I'd like to collect a list\n",
      "of issues with this license (if any) with respect to non-free and see\n",
      "if Intel is willing to change them. The one that sticks out to me is:\n",
      "\n",
      " * Section 4: \"Updates\" requires \"commerically reasonable efforts\" to\n",
      "   supply our \"customers\" with updates that Intel distributes. If this\n",
      "   means we cannot say no to an update from Intel, that does not sound\n",
      "   reasonable for non-free. But perhaps we are exempt from this since\n",
      "   1) non-free isn't officially part of Debian and 2) we are a\n",
      "   non-commercial entity making commercially feasibility null? \n",
      "\n",
      "-- \n",
      "dann frazier\n",
      "\n",
      "\n",
      "-- \n",
      "To UNSUBSCRIBE, email to debian-legal-REQUEST@lists.debian.org\n",
      "with a subject of \"unsubscribe\". Trouble? Contact listmaster@lists.debian.org\n",
      "\n",
      "                 \n",
      "\n",
      "cE uwb5Ezsmt h,q\n"
     ]
    }
   ],
   "source": [
    "sample_path = 'data/spam2-train/aahkoctdmjnikvon.0'\n",
    "print(extract_body_from_email(sample_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454ed7a",
   "metadata": {},
   "source": [
    "looks good, doing all and start experimenting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05932b1c",
   "metadata": {},
   "source": [
    "Here storing preprocessed emails in data X and labels y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38571160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, labels_file):\n",
    "    \"\"\"\n",
    "    Loads all emails and their labels into memory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the folder containing the email files\n",
    "        labels_file (str): Path to the labels file\n",
    "    Returns:\n",
    "        X (list of str): List of preprocessed email bodies\n",
    "        y (list of int): List of labels (0 = ham, 1 = spam)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    with open(labels_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            filepath, label = line.strip().split(\";\")\n",
    "            label = int(label)\n",
    "            filename = os.path.basename(filepath)\n",
    "\n",
    "            # Full path to the email file\n",
    "            email_path = os.path.join(data_dir, filename)\n",
    "\n",
    "            # Get the clean text body\n",
    "            text = extract_body_from_email(email_path)\n",
    "\n",
    "            X.append(text)\n",
    "            y.append(label)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c2d31e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset(\"data/spam2-train\", \"spam2-train.labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7595ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18756 18756\n",
      "Ok, so I see now that reg_alloc is rounded up to a multiple of 8 by\n",
      "the following two lines:\n",
      "\n",
      "   /*code*/ const int slot = (reg_alloc + 7) >> 3;\n",
      "   /*code*/ reg_alloc = slot << 3;\n",
      "\n",
      "However, this still begs the question of what the slot variable is\n",
      "for. Clearly it's being used as an index into\n",
      "interp\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(len(X), len(y))\n",
    "print(X[0][:300])  # preview first email\n",
    "print(y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c36233",
   "metadata": {},
   "source": [
    "3. Extract Features and Vectorize the Text\n",
    "\n",
    "Next, you need to convert the cleaned text into numerical features that can be used by the machine learning model.\n",
    "\n",
    "TF-IDF Vectorizer: This is the most common method for text data. It transforms the text into a sparse matrix of term frequencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
